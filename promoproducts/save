# -*- coding: utf-8 -*-

import urllib
import pdb
import promoproducts
from bs4 import BeautifulSoup
from promoproducts import Promoproducts

class Store(object):
    def __init__(self):
        self.encoding = Promoproducts().encoding
        self.stores = Promoproducts().get_stores()
        self.sores_url = [
                            'www.extra.com.br',
                            'www.pontofrio.com.br',
                            'www.walmart.com.br',
                            'www.ricardoeletro.com.br'
        ]
        # self.departments = [
        #                         'Beleza e Saúde', 'Brinquedos',
        #                         'Cama, Mesa e Banho', 'Eletrodomésticos',
        #                         'Eletroportáteis', 'Esporte e Lazer', 'Games',
        #                         'Informática', 'Livros', 'Tablets',
        #                         'Telefones e Celulares', 'TV e Vídeo',
        #                         'Telefonia', 'Eletrônicos'
        # ]

        self.departments = ['Eletrodomésticos']



    def get_extra_departments(self):
        # using for Extra and Ponto Frio

        # HTML of coupons page
        html = urllib.urlopen("http://www.extra.com.br").read()

        # making a soup
        soup = BeautifulSoup(html, from_encoding = self.encoding)

        depts = soup.select('li.nav-item-todos li.navsub-item a')










        for dept in depts:





            if dept.text.encode('utf8') in self.departments:
                # HTML of department page
                html = urllib.urlopen(dept['href']).read()

                # making a soup
                soup = BeautifulSoup(html)

                # all categories available
                categories = soup.select('div.navigation h3.tit > a')

                # categories and names
                ca = []

                for c in categories:

                    # products info
                    collected_products = []

                    first_time = True

                    # just for loop works for the first time
                    next_page = True

                    while next_page:

                        if first_time:
                            # HTML of category page
                            html = urllib.urlopen(c['href']).read()

                            # making a soup
                            soup = BeautifulSoup(html)

                            # prods from page
                            products = soup.select('div.lista-produto div.hproduct')
                            first_time = False
                        else:
                            # HTML of category page
                            html = urllib.urlopen(url_next_page).read()

                            # making a soup
                            soup = BeautifulSoup(html)

                            # prods from page
                            products = soup.select('div.lista-produto div.hproduct')

                        # infos of single prod
                        for p in products:
                            # if prod is available then will be 1
                            available = 1

                            # prod price
                            from_price = p.find('span', attrs={'class': 'from price regular'})
                            on_sale = p.find('span', attrs={'class': 'for price sale'})

                            if on_sale is None:
                                on_sale = "R$ 0"
                                available = 0 # when the product is not available
                            else:
                                on_sale = on_sale.strong.text

                            if from_price is None:
                                from_price = on_sale
                            else:
                                from_price = from_price.strong.text

                            # all info of prod together
                            prod = {
                                "name": p.a['title'],
                                "img": p.span.img['data-src'],
                                "href": p.a['href'],
                                "from_price": from_price,
                                "on_sale": on_sale,
                                "available": available,
                            }

                            print(prod)

                            collected_products.append(prod)

                        url_next_page = soup.select('div.pagination li.next > a')
                        print(url_next_page)

                        if not url_next_page:
                            print(url_next_page)
                            next_page = False
                        else:
                            url_next_page = url_next_page[0]['href']


                    ca.append(
                        {
                            "name": c.text.encode('utf-8'),
                            "href": c['href'],
                            "products": collected_products
                         })

                dept = {
                    "store": "Extra",
                    "name": dept['title'],
                    "href": dept['href'],
                    "categories": ca
                }








        return self.departments






    def get_extra_categories(self, depts_list):
        """
        Get all categories from Extra departments.
        E.g. Bonecos, Playground etc from Brinquedos

        Args:
            :param dept: (list) a list of departments link in HTML tag (<a>)

        Return:
            :return: Returns a list of categories
        """

        for dept in depts_list:
            if dept.text.encode('utf8') in self.departments:
                # HTML of department page
                html = urllib.urlopen(dept['href']).read()

                # making a soup
                soup = BeautifulSoup(html)

                # all categories available
                categories = soup.select('div.navigation h3.tit > a')

                # categories and names
                ca = []

        return categories






    def get_pf_departments(self):
        # using for Extra

        # HTML of coupons page
        html = urllib.urlopen("http://www.pontofrio.com.br").read()

        # making a soup
        soup = BeautifulSoup(html)

        depts = soup.select('li.todasCategorias div.sbmn ul:not(:last-child) li a')

        return len(depts)











    def get_products(self):
        """
        Get all products from store.

        Return:
            :return: Returns a list of products
        """

        url = self.coupon_url(store)

        # HTML of product page
        html = urllib.urlopen(url).read()

        # making a soup
        soup = BeautifulSoup(html)
